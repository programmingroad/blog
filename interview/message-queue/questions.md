### 为什么使用消息队列？

三个核心场景：解耦，异步，削峰

解耦：调用第三方接口推送告警(添加消息队列解耦)

异步：上述也可以用到异步场景(跨网闸耗时)

削峰：没有用到()

### 消息队列都有什么优缺点？

缺点：
1. 系统可用性降低(mq出故障系统崩溃)，系统引入的外部依赖越多，越容易挂掉
2. 导致系统要考虑的问题变多，进而导致系统复杂性变高。硬生生加个mq进来，怎么保证消息没有重复消费？怎么处理消息丢失的情况？怎么保证消息传递的顺序性？
3. 一致性问题

### kafka,activemq,rabbitmq,rocketmq都有什么区别以及适合哪些场景？

特性|ActiveMQ|RabbitMQ|RocketMQ|Kafka
---|---|---|---|---
单机吞吐量|万级，吞吐量比RocketMQ和Kafka要低了一个数量级|万级，吞吐量比RocketMQ和Kafka要低了一个数量级|10万级，RocketMQ也是可以支撑高吞吐的一种MQ|10万级，这是Kafka最大的优点，就是吞吐量高 一般配合大数据类的系统来进行实时数据计算，日志采集等场景
topic数量对吞吐量的影响|||topic可以达到几百，几千个的级别，吞吐量会有较小幅度的下降 这是RocketMQ的一大优势，在同等机器下，可以支撑大量的topic|topic从几十个到几百个的时候，吞吐量会大幅度下降 所以在同等机器下，kafka尽量保证topic数量不要过多，如果支撑大规模topic。需要增加更多的机器资源
时效性|ms级|微秒级，这是rabbitmq的一大特点，延迟是最低的|ms级|延迟在ms级以内
可用性|高，基于主从架构实现高可用性|高，基于主从架构实现高可用性|非常高，分布式架构|非常高，kafka是分布式的，一个数据多个副本，少数机器宕机，不会丢失数据，不会导致不可用
消息可靠性|有较低概率丢失数据||经过参数优化配置，可以做到0丢失|经过参数优化配置，消息可以做到0丢失
功能支持|MQ领域的功能及其完备|基于erlang开发，所以并发能力很强，性能极其好，延时很低|MQ功能较为完善，还是分布式的，扩展性好|功能较为简单，主要支持简单的MQ功能，在大数据领域的实时计算以及日志采集被大规模使用，是事实上的标准
优劣势总结|非常成熟，功能强大，在业内大量公司以及项目中都有应用 偶尔会有较低概率丢失消息，而且现在社区以及国内应用都越来越少，官方社区现在对ActiveMQ5.x维护越来越少，而且确实主要是基于解耦和异步来用的，较少在大规模吞吐的场景中使用|erlang语言开发，性能极其好；而且开源提供的管理界面非常棒，用起来很好用，在国内一些互联网公司近几年用rabbitmq也比较多一些 但是问题也显而易见，rabbitmq确实吞吐量会低一些，这是因为它做的实现机制比较重。而且erlang开发，国内有几个公司有实力做erlang源码级别的研究和定制？而且rabbitmq集群动态扩展会很麻烦，不过这个还好。其实主要是erlang语言本身带来的问题，很难度源码，很难定制和掌控|接口简单易用，而且毕竟在阿里大规模应用过，有阿里品牌保障 日处理消息上百亿之多，可以做到大规模吞吐，性能也非常好，分布式扩展也很方便，社区维护还可以，可靠性和可用性都是ok的，还可以支撑大规模的topic数量，支持复杂的mq业务场景 而且一个很打的优势在于，阿里出品都是java系的，我们可以自己阅读源码，定制自己公司的mq，可以掌控 社区活跃度相对较为一般，不过也还可以，文档相对来说简单一些，然后接口这块不是按照标准jms规范走的有些系统要迁移需要修改大量代码 还有就是阿里出台的技术，你得做好这个技术万一被抛弃，社区黄掉的风险，那如果你们公司有技术实力，RocketMQ挺好的|kafka的特点其实很明显，就是仅仅提供较小的核心功能，但是提供超高的吞吐量，ms级的延迟，极高的可用性以及可靠性，而且分布式可以任意扩展 同时kafka最好是支撑较少的topic数量即可，保证其超高吞吐量 而且kafka唯一的一点劣势是有可能消息重复消费，那么对数据准确性会造成极其轻微的影响，在大数据领域中以及日志采集中，这点轻微影响可以忽略 这个特性天然适合大数据实时计算以及日志收集

### 如果让你来设计一个消息队列，该如何进行架构设计？说一下思路？

1. 分布式(参考kafka设计理念)
2. 持久化(是否需要持久化到磁盘)
3. 高可用(参考kafka机制)
4. 如何保证数据不丢
5. 如何保证数据的顺序性

### 如何解决消息队列的延时以及过期失效问题？  消息队列满了以后该怎么处理？ 消息持续挤压几个小时，该怎么解决？

1. 消费者挂掉导致mq积压了大量数据，先让消费者恢复工作，使原来的消费者将消费的数据写入到一个临时的mq中去，然后启动之前消费者几倍的消费者去消费
2. mq过期数据，只能后续手动查一条一条处理
3. 磁盘满了，启动临时消费者丢弃，再使用第二个方案补发